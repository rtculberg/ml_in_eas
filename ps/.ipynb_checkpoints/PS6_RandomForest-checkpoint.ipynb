{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81484c95-7ca3-40c9-ba8d-b0dbc5da5deb",
   "metadata": {},
   "source": [
    "# Problem Set 6 - Random Forest Regression    \n",
    "\n",
    "In this problem set, you will train a random forest regression model to emulate a physics-based firn model in order to predict changes in firn air content on Antarctica ice shelves out through the end of the century. Firn air content (FAC) is a good proxy measure for how much meltwater can be retained by an ice shelf, so higher FAC means that the ice shelf is more stable and less prone to hydrofracture-induced disintegration. By predicting how FAC will change with time under different emissions scenarios, we can estimate the vulnerability of these ice shelves to damage and failure in a changing climate.    \n",
    "\n",
    "The data and workflow in this problem set are adapted from D. Dunmire, N. Wever, A. F. Banwell, J. T. M. Lenaerts (2024) \"Antarctic-wide ice-shelf firn emulation reveals robust future firn air depletion signal for the Antarctic Peninsula,\" *Nature Communications Earth and Environment, 5 (1)*, 1-13, doi: 10.1038/s43247-024-01255-4.\n",
    "\n",
    "We are motivated to use a machine learning model to make these predictions because of the huge computational cost for physics-based models. Dunmire et al. (2024) notes that SNOWPACK model runs used to generate the training data for FAC took multiple days of CPU time, while their random forest emulator was able to estimate FAC time series for around 6 million datapoints in just under 40 minutes. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df5ff2f1-99e4-4114-afc3-e57fa224b6e5",
   "metadata": {},
   "source": [
    "**[1]** Import the packages that you will need to train a random forest regression model and optimize its hyperparameters using a randomized search. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74dad38a-f18f-454b-be15-009676e9f1c5",
   "metadata": {},
   "source": [
    "**[2] (2 pts)** Import the training and test data from https://raw.githubusercontent.com/rtculberg/ml_in_eas/main/data/FACTrainingData.csv. Separately, import data from a witheld set of ice shelves from https://raw.githubusercontent.com/rtculberg/ml_in_eas/main/data/WithheldIceShelves.csv. Print the first few rows from the training and test data set.           \n",
    "\n",
    "You should see that you have access to the following variables:   \n",
    "**year** - the year of the data point       \n",
    "**site** - an alphanumeric code for test locations on different ice shelves          \n",
    "**snow** - total annual snow accumulation in millimeters of water equivalent         \n",
    "**wind** - average annual 10 m windspeed in meters per second         \n",
    "**ta_summer** - average 2 m summer air temperature in degrees C          \n",
    "**ta_annual** - average 2 m annual air temperature in degrees C        \n",
    "**fac** - firn air content in meters at simulated by the physics-based SNOWPACK model        \n",
    "**SSP** - share socioeconomic pathway scenario (e.g. scenarios for different degrees of carbon emissions in the future)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94378bc4-89e2-49cd-a8fb-f759bc558ac4",
   "metadata": {},
   "source": [
    "**[3] (5 pts)** From the test and training dataset, create one new dataframe that contains only the input features and another new dataframe with the target feature. Split the data into test and training sets using an 80-20 split. Remember to set your random state to some integer for reproducibility."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f33f70-1068-4d96-8188-0748bd0493f4",
   "metadata": {},
   "source": [
    "**[4] (5 pts)** Apply a z-score transform to both your training and test data sets. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2be2874-4885-4caa-8eea-dd1b88934a66",
   "metadata": {},
   "source": [
    "**[5] (5 pts)** A random forest regression model has a large number of tunable hyperparameters. To choose the best paramters, we will use `RandomizedSearchCV` to try many different combinations and see how they score. To do this, we need to set up a random grid with different parameter ranges to explore. Create a Python dictionary that contains lists of possible parameters values for the following hyperparameters:      \n",
    "`n_estimators: [10,50,100,200]`         \n",
    "`max_features: [None, 'sqrt']`             \n",
    "`max_depth: [5,10,25,50,100,None]`             \n",
    "`min_samples_split: [2,5,10]`           \n",
    "`min_samples_leaf: [1,2,4]`             "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e4976f-4bb7-4f19-a082-6c9a71bc40ae",
   "metadata": {},
   "source": [
    "**[6] (5 pts)** Instantiate a new `RandomForestRegressor()` object. Pass this object to `RandomizedSearchCV` as the `estimator`. Pass your random grid dictionary that you created in the last code block as the `param_distribution` parameters. Run 100 interations using three-fold cross-validation. Set the `random_state` to the same integer that you used for the test/train split and `n_jobs` to -1 to use all available cores. Then call the `fit()` function on your new `RandomizedSearchCV` object, passing it your training data, to find the best combination of parameters. Note that this code may take a few minutes to run!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c2afde2-144e-473c-8695-9a1dcc03417b",
   "metadata": {},
   "source": [
    "**[7] (2 pts)** Find and print out the best parameters from your randomized search. Hint: look at the documentation for the `best_params_` property of a `RandomizedSearchCV` object. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3b5a28-fcbe-48d7-8364-1d11bcbdfc16",
   "metadata": {},
   "source": [
    "**[8] (5 pts)** Now that we have selected the best hyperparameters, it's time to actually train our best version of the model! Instantiate a new `RandomForestRegressor` object using the best hyperparameter values that you found in your randomized search. Set the random state to the same integer that you used in the random search. Make sure your random forest regressor will use bootstrapping to build the trees and be sure to use out-of-bag samples to estimate the generalization score.     \n",
    "\n",
    "Train your model using your training data. Then print out the R^2 training score, the R^2 score on the test set, the score of the training dataset using the out-of-bag estimate, and the feature importance weighting. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384a2121-d31b-4a19-9f67-d7ff4cf5c88d",
   "metadata": {},
   "source": [
    "**[9] (5 pts)** Use your trained model to predict FAC on the test dataset. Calculate and print out the R^2 score for the test dataset. Print the RMSE score, rescaled to FAC units in meters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcecba09-c0cd-4df6-bb7d-59ae1d298268",
   "metadata": {},
   "source": [
    "**[10] (3 pts)** Make a scatter plot of the true vs. predicted FAC on the test set. Be sure to \"un-standardize\" the data before plotting so that your axes are in terms of true FAC in meters. Plot a 1-1- line on top of your scatter plot.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a0b74d-ac33-46d6-9982-39e75659cb4b",
   "metadata": {},
   "source": [
    "**[11]** Now we can use our trained model emulator to make predictions of how FAC will change on other ice shelves through the end of the century. The code below selects some test points from the Larsen C ice shelf under different SSP scenarios for this exercise. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "de374bfe-f10b-4e8a-ac74-91ca66d23c1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>snow</th>\n",
       "      <th>wind</th>\n",
       "      <th>ta_summer</th>\n",
       "      <th>ta_annual</th>\n",
       "      <th>SSP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020</td>\n",
       "      <td>699.2070</td>\n",
       "      <td>5.267815</td>\n",
       "      <td>-2.533384</td>\n",
       "      <td>-12.772272</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020</td>\n",
       "      <td>797.8020</td>\n",
       "      <td>5.646286</td>\n",
       "      <td>-1.729275</td>\n",
       "      <td>-11.357697</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020</td>\n",
       "      <td>929.5386</td>\n",
       "      <td>4.920175</td>\n",
       "      <td>-2.362071</td>\n",
       "      <td>-12.070659</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2021</td>\n",
       "      <td>721.8876</td>\n",
       "      <td>5.306538</td>\n",
       "      <td>-2.488674</td>\n",
       "      <td>-12.412049</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2021</td>\n",
       "      <td>824.7402</td>\n",
       "      <td>5.689971</td>\n",
       "      <td>-1.712857</td>\n",
       "      <td>-10.976377</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    year      snow      wind  ta_summer  ta_annual  SSP\n",
       "1   2020  699.2070  5.267815  -2.533384 -12.772272    5\n",
       "2   2020  797.8020  5.646286  -1.729275 -11.357697    5\n",
       "3   2020  929.5386  4.920175  -2.362071 -12.070659    5\n",
       "12  2021  721.8876  5.306538  -2.488674 -12.412049    5\n",
       "13  2021  824.7402  5.689971  -1.712857 -10.976377    5"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Larsen C\n",
    "LC = unseen[((unseen.site == 'VIR619')|(unseen.site == 'VIR621')|(unseen.site == 'VIR575'))].copy()\n",
    "LC.drop(['site', 'fac'], axis=1, inplace=True)\n",
    "LC.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a56da21f-14f6-40d4-8dad-3f82ad0aca92",
   "metadata": {},
   "source": [
    "**[12] (2 pts)** Standardize thew ne unseen data for input to the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2030e655-8364-4ef1-83f2-bcc752703047",
   "metadata": {},
   "source": [
    "**[13] (5 pts)** Use your trained model to predict FAC for each data point. Rescale your predictions back to meters. Add your predictions to your `LC` dataframe as a new column and print the first few rows of that dataframe. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de5d62da-37d1-4b2d-83fb-d65bbd286272",
   "metadata": {},
   "source": [
    "**[14] (1 pt)** The code below shows you how to select data points from the SSP5 emission scenario and find the mean FAC for each year in the dataset. Use this examples to create two more variables that hold data for the SSP3 and SSP1 emission scenarios. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "74700ddd-11e0-4b43-a214-81ac8a2eea35",
   "metadata": {},
   "outputs": [],
   "source": [
    "LC5 = LC[LC.SSP == 5].groupby(LC.year).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377c55b9-b389-4729-82b5-3156ac5ce2c7",
   "metadata": {},
   "source": [
    "**[15] (5 pts)** For each of the three emission scenarios, plot annual mean FAC as a function of time. Plot all three lines on the same plot. Don't forget to label your axes correctly and provide a legend."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EAS6920: ML in EAS",
   "language": "python",
   "name": "ml_in_eas"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
